{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yTl25s_UHtL",
        "outputId": "9acefae7-ad58-49bd-9ef6-619559cb8e3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tNLZ8w6G86Ye"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = '/content/drive/MyDrive/WCE Image Localization YOLOV8/Folder'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBHdWXvXM3qC"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "dg6_8Xay3ctg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy7BcAyj9LvW",
        "outputId": "9112a778-18e7-458d-c6bc-e00d798c79c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.190 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/content/drive/MyDrive/WCE Image Localization YOLOV8/data.yaml, epochs=5, patience=50, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
            "Model summary: 295 layers, 25856899 parameters, 25856883 gradients, 79.1 GFLOPs\n",
            "\n",
            "Transferred 469/475 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/WCE Image Localization YOLOV8/Folder/Train/labels.cache... 1169 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1169/1169 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/WCE Image Localization YOLOV8/Folder/Valid/labels.cache... 70 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        1/5         0G      1.691      2.237      1.771          3        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [14:28<00:00, 11.74s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.32s/it]\n",
            "                   all         70         70      0.288     0.0286     0.0216    0.00892\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        2/5         0G      1.724      2.104      1.754          1        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [14:05<00:00, 11.43s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.07s/it]\n",
            "                   all         70         70    0.00366      0.186    0.00262   0.000848\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        3/5         0G      1.688      2.044      1.766          3        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [13:54<00:00, 11.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:19<00:00,  6.60s/it]\n",
            "                   all         70         70      0.277      0.114      0.118     0.0403\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        4/5         0G      1.596      1.933      1.703          2        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [13:49<00:00, 11.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:20<00:00,  6.96s/it]\n",
            "                   all         70         70      0.223        0.4        0.2      0.108\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        5/5         0G      1.549      1.918       1.67          1        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [13:49<00:00, 11.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:19<00:00,  6.55s/it]\n",
            "                   all         70         70      0.133      0.243     0.0799     0.0333\n",
            "\n",
            "5 epochs completed in 1.204 hours.\n",
            "Optimizer stripped from runs/detect/train3/weights/last.pt, 52.0MB\n",
            "Optimizer stripped from runs/detect/train3/weights/best.pt, 52.0MB\n",
            "\n",
            "Validating runs/detect/train3/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.190 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 218 layers, 25840339 parameters, 0 gradients, 78.7 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:23<00:00,  7.97s/it]\n",
            "                   all         70         70      0.223        0.4        0.2      0.108\n",
            "Speed: 0.4ms preprocess, 322.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7d43c2728d90>\n",
              "fitness: 0.11680688262373415\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([     0.1076])\n",
              "names: {0: 'bleeding'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.2233679695473558, 'metrics/recall(B)': 0.4, 'metrics/mAP50(B)': 0.19964517087607717, 'metrics/mAP50-95(B)': 0.10760262837347381, 'fitness': 0.11680688262373415}\n",
              "save_dir: PosixPath('runs/detect/train3')\n",
              "speed: {'preprocess': 0.4007032939365932, 'inference': 322.7056401116508, 'loss': 0.00019073486328125, 'postprocess': 0.8339847837175642}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = YOLO('yolov8m.pt')  # load a pretrained model \n",
        "model.train(data='/content/drive/MyDrive/WCE Image Localization YOLOV8/data.yaml', epochs=5, imgsz=224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZt7FiKD9NVR",
        "outputId": "d5e3038c-5eca-415d-822f-e905006a6848"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.190 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/WCE Image Localization YOLOV8/Folder/Valid/labels.cache... 70 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:20<00:00,  4.12s/it]\n",
            "                   all         70         70      0.223        0.4        0.2      0.108\n",
            "Speed: 0.5ms preprocess, 269.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([     0.1076])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics = model.val()  \n",
        "metrics.box.map    \n",
        "metrics.box.map50  \n",
        "metrics.box.map75  \n",
        "metrics.box.maps   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R477QRz04iNq",
        "outputId": "55d76ecd-5180-4da6-cc7e-a629e8ac5caf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/runs/ (stored 0%)\n",
            "  adding: content/runs/detect/ (stored 0%)\n",
            "  adding: content/runs/detect/train3/ (stored 0%)\n",
            "  adding: content/runs/detect/train3/val_batch1_pred.jpg (deflated 18%)\n",
            "  adding: content/runs/detect/train3/val_batch0_pred.jpg (deflated 17%)\n",
            "  adding: content/runs/detect/train3/val_batch2_labels.jpg (deflated 21%)\n",
            "  adding: content/runs/detect/train3/F1_curve.png (deflated 22%)\n",
            "  adding: content/runs/detect/train3/labels.jpg (deflated 22%)\n",
            "  adding: content/runs/detect/train3/PR_curve.png (deflated 24%)\n",
            "  adding: content/runs/detect/train3/results.png (deflated 7%)\n",
            "  adding: content/runs/detect/train3/train_batch1.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/train3/R_curve.png (deflated 18%)\n",
            "  adding: content/runs/detect/train3/val_batch2_pred.jpg (deflated 21%)\n",
            "  adding: content/runs/detect/train3/results.csv (deflated 79%)\n",
            "  adding: content/runs/detect/train3/val_batch1_labels.jpg (deflated 16%)\n",
            "  adding: content/runs/detect/train3/train_batch0.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/train3/confusion_matrix.png (deflated 39%)\n",
            "  adding: content/runs/detect/train3/events.out.tfevents.1696235506.3a3bc8185669.185.2 (deflated 91%)\n",
            "  adding: content/runs/detect/train3/args.yaml (deflated 50%)\n",
            "  adding: content/runs/detect/train3/val_batch0_labels.jpg (deflated 17%)\n",
            "  adding: content/runs/detect/train3/train_batch2.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/train3/P_curve.png (deflated 15%)\n",
            "  adding: content/runs/detect/train3/confusion_matrix_normalized.png (deflated 37%)\n",
            "  adding: content/runs/detect/train3/labels_correlogram.jpg (deflated 40%)\n",
            "  adding: content/runs/detect/train3/weights/ (stored 0%)\n",
            "  adding: content/runs/detect/train3/weights/last.pt (deflated 8%)\n",
            "  adding: content/runs/detect/train3/weights/best.pt (deflated 8%)\n",
            "  adding: content/runs/detect/val/ (stored 0%)\n",
            "  adding: content/runs/detect/val/val_batch1_pred.jpg (deflated 18%)\n",
            "  adding: content/runs/detect/val/val_batch0_pred.jpg (deflated 17%)\n",
            "  adding: content/runs/detect/val/val_batch2_labels.jpg (deflated 16%)\n",
            "  adding: content/runs/detect/val/F1_curve.png (deflated 22%)\n",
            "  adding: content/runs/detect/val/PR_curve.png (deflated 24%)\n",
            "  adding: content/runs/detect/val/R_curve.png (deflated 18%)\n",
            "  adding: content/runs/detect/val/val_batch2_pred.jpg (deflated 18%)\n",
            "  adding: content/runs/detect/val/val_batch1_labels.jpg (deflated 17%)\n",
            "  adding: content/runs/detect/val/confusion_matrix.png (deflated 39%)\n",
            "  adding: content/runs/detect/val/val_batch0_labels.jpg (deflated 17%)\n",
            "  adding: content/runs/detect/val/P_curve.png (deflated 15%)\n",
            "  adding: content/runs/detect/val/confusion_matrix_normalized.png (deflated 37%)\n",
            "  adding: content/runs/detect/train2/ (stored 0%)\n",
            "  adding: content/runs/detect/train2/val_batch1_pred.jpg (deflated 18%)\n",
            "  adding: content/runs/detect/train2/val_batch0_pred.jpg (deflated 17%)\n",
            "  adding: content/runs/detect/train2/val_batch2_labels.jpg (deflated 21%)\n",
            "  adding: content/runs/detect/train2/F1_curve.png (deflated 22%)\n",
            "  adding: content/runs/detect/train2/labels.jpg (deflated 22%)\n",
            "  adding: content/runs/detect/train2/PR_curve.png (deflated 24%)\n",
            "  adding: content/runs/detect/train2/results.png (deflated 7%)\n",
            "  adding: content/runs/detect/train2/train_batch1.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/train2/R_curve.png (deflated 18%)\n",
            "  adding: content/runs/detect/train2/val_batch2_pred.jpg (deflated 21%)\n",
            "  adding: content/runs/detect/train2/results.csv (deflated 79%)\n",
            "  adding: content/runs/detect/train2/val_batch1_labels.jpg (deflated 16%)\n",
            "  adding: content/runs/detect/train2/train_batch0.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/train2/confusion_matrix.png (deflated 39%)\n",
            "  adding: content/runs/detect/train2/args.yaml (deflated 50%)\n",
            "  adding: content/runs/detect/train2/val_batch0_labels.jpg (deflated 17%)\n",
            "  adding: content/runs/detect/train2/train_batch2.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/train2/events.out.tfevents.1696230609.3a3bc8185669.185.1 (deflated 91%)\n",
            "  adding: content/runs/detect/train2/P_curve.png (deflated 15%)\n",
            "  adding: content/runs/detect/train2/confusion_matrix_normalized.png (deflated 37%)\n",
            "  adding: content/runs/detect/train2/labels_correlogram.jpg (deflated 40%)\n",
            "  adding: content/runs/detect/train2/weights/ (stored 0%)\n",
            "  adding: content/runs/detect/train2/weights/last.pt (deflated 8%)\n",
            "  adding: content/runs/detect/train2/weights/best.pt (deflated 8%)\n",
            "  adding: content/runs/detect/train/ (stored 0%)\n",
            "  adding: content/runs/detect/train/events.out.tfevents.1696230279.3a3bc8185669.185.0 (deflated 9%)\n",
            "  adding: content/runs/detect/train/args.yaml (deflated 50%)\n",
            "  adding: content/runs/detect/train/weights/ (stored 0%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r folder_name.zip /content/runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9W6OkLRd4oSv",
        "outputId": "50657183-8f68-4a1b-d086-32821115ea92"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_ce36acf3-3873-4200-aead-e1b2216ae5f6\", \"runs.zip\", 195621235)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/runs.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDldCUwU0B0F",
        "outputId": "a758c409-ad37-4b63-c03e-99568e83dbf1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /content/A0129.png: 224x224 1 bleeding, 229.3ms\n",
            "Speed: 0.7ms preprocess, 229.3ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 224)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'bleeding'}\n",
              " orig_img: array([[[0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0],\n",
              "         [0, 0, 0]]], dtype=uint8)\n",
              " orig_shape: (224, 224)\n",
              " path: '/content/A0129.png'\n",
              " probs: None\n",
              " save_dir: None\n",
              " speed: {'preprocess': 0.7061958312988281, 'inference': 229.34222221374512, 'postprocess': 0.9782314300537109}]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = model('/content/A0129.png', conf=0.1)\n",
        "result # Lower confidence threshold"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
